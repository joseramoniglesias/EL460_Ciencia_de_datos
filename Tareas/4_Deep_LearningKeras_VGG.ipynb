{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e2de4f",
   "metadata": {},
   "source": [
    "Entrenando la arquitectura VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e330b6",
   "metadata": {},
   "source": [
    "Keras tiene a nuestra disposición tanto la arquitectura VGG-16 como la VGG-19. Vamos a entrenar ambas y una más que explicaremos en breve. Debido a que vamos a usar la definida en Keras (aunque podríamos crearla directamente), debemos aumentar el tamaño de las imágenes a 48 píxeles. Para ello, usaremos el siguiente código:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756c84d",
   "metadata": {},
   "source": [
    "Importando Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc69513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from IPython.display import SVG\n",
    "import cv2\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras import layers\n",
    "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.utils import layer_utils, np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import losses\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a2ab8",
   "metadata": {},
   "source": [
    "Preparando el conjunto de datos\n",
    "Como antes, usaremos el conjunto de datos CIFAR-100, que, como ya dijimos, consta de 600 imágenes por cada clase de un total de 100 clases. Se divide en 500 imágenes para entrenamiento y 100 imágenes para validación por cada clase. Las 100 clases están agrupadas en 20 superclases. Cada imagen tiene una etiqueta \"fina\" (la clase, de entre las 100, a la que pertenece) y una etiqueta \"gruesa\" (correspondiente a su superclase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5338c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b3324",
   "metadata": {},
   "source": [
    "Actualmente, hemos descargado los datasets de entrenamiento y validación. x_train_original y x_test_original son los conjuntos de datos con lás imágenes de entrenamiento y validación respectivamente, mientras que y_train_original y y_test_original son los datasets con las etiquetas.\n",
    "\n",
    "Veamos la forma de y_train_original:\n",
    "    array([[19], [29], [ 0], ..., [ 3], [ 7], [73]])  \n",
    "    \n",
    "Como se puede ver, se trata de un array donde cada número se corresponde con la etiqueta concreta. Lo primero que hay que hacer es convertir este array en su versión one-hot-encoding    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225bd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_original, 100)\n",
    "y_test = np_utils.to_categorical(y_test_original, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852af62",
   "metadata": {},
   "source": [
    "Bien, representa la imagen en los 3 canales RGB de 256 píxeles. Vamos a verla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23ffbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(x_train_original[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab735c",
   "metadata": {},
   "source": [
    "Lo que haremos a continuación, es normalizar las imágenes. Esto es, dividiremos cada elemento de x_train_original y xtestoriginal por el numero de píxeles, es decir, 255. Con esto obtenemos que el array comprenderá valores de entre 0 y 1. Con esto el entrenamiento suele aportar mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c8874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_original/255  \n",
    "x_test = x_test_original/255  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a8f15",
   "metadata": {},
   "source": [
    "Preparando el entorno\n",
    "El siguiente paso es definir ciertos parámetros sobre el experimento en Keras. Lo primero será especificar a Keras dónde se encuentran los canales. En un array de imágenes, pueden venir como último indice o como el primero. Esto se conoce como canales primero (channels first) o canales al final (channels last). En nuestro caso, vamos a definirlos al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615c6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678e7df",
   "metadata": {},
   "source": [
    "Lo siguiente que vamos a especificar es la fase del experimento. En este caso, la fase será de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a22e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INVITADO_0310\\anaconda3\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c76336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [195, 205, 193],\n",
       "        [212, 224, 204],\n",
       "        [182, 194, 167]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        ...,\n",
       "        [170, 176, 150],\n",
       "        [161, 168, 130],\n",
       "        [146, 154, 113]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [254, 254, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [189, 199, 169],\n",
       "        [166, 178, 130],\n",
       "        [121, 133,  87]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[148, 185,  79],\n",
       "        [142, 182,  57],\n",
       "        [140, 179,  60],\n",
       "        ...,\n",
       "        [ 30,  17,   1],\n",
       "        [ 65,  62,  15],\n",
       "        [ 76,  77,  20]],\n",
       "\n",
       "       [[122, 157,  66],\n",
       "        [120, 155,  58],\n",
       "        [126, 160,  71],\n",
       "        ...,\n",
       "        [ 22,  16,   3],\n",
       "        [ 97, 112,  56],\n",
       "        [141, 161,  87]],\n",
       "\n",
       "       [[ 87, 122,  41],\n",
       "        [ 88, 122,  39],\n",
       "        [101, 134,  56],\n",
       "        ...,\n",
       "        [ 34,  36,  10],\n",
       "        [105, 133,  59],\n",
       "        [138, 173,  79]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_original[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a83b41",
   "metadata": {},
   "source": [
    "Entrenando una red neuronal VGG\n",
    "En primer lugar, vamos a entrenar una red neuronal sencilla. Definimos un procedimiento que nos devuelva una red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e68041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(data):  \n",
    "    data_upscaled = np.zeros((data.shape[0], 48, 48, 3))\n",
    "    for i, img in enumerate(data):\n",
    "        large_img = cv2.resize(img, dsize=(48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "        data_upscaled[i] = large_img\n",
    "\n",
    "    return data_upscaled\n",
    "\n",
    "x_train_resized = resize_data(x_train_original)  \n",
    "x_test_resized = resize_data(x_test_original)  \n",
    "x_train_resized = x_train_resized / 255  \n",
    "x_test_resized = x_test_resized / 255  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca90f55",
   "metadata": {},
   "source": [
    "Con esto, tenemos las imágenes a 48 píxeles normalizadas en x_train_resized y x_test_resized. Como dijimos antes, entrenaremos los modelos VGG-16, VGG-19 y uno más. Esta es nuestra propia versión de VGG con objeto de no tener que modificar el tamaño de las imágenes. Empezaremos entrenando VGG-16, veremos resultados y continuaremos con VGG-19 para terminar con nuestra Custom VGG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7b0cf",
   "metadata": {},
   "source": [
    "VGG-16\n",
    "Definimos el modelo. Tan fácil como llamar al existente en Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f7f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "def create_vgg16():  \n",
    "  model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(48,48,3), pooling=None, classes=100)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5caaf",
   "metadata": {},
   "source": [
    "Los parámetros son sencillos: vamos a incluir una red neuronal densa al final con el parámetro include_top. No cargamos ningún modelo entrenado a priori con el parámetro weights. No especificamos ningún tensor de keras como entrada con input_tensor. Definimos la forma de los datos de entrada con input_shape, No especificamos Pooling final con pooling y definimos el número de clases final con classes.\n",
    "\n",
    "Una vez definido el modelo, lo compilamos especificando la función de optimización, la de coste o pérdida y las métricas que usaremos. En este caso, como en los artículos anteriores, usaremos la función de optimización stochactic gradient descent, la función de pérdida categorical cross entropy y, para las métricas, accuracy y mse (media de los errores cuadráticos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec949f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = create_vgg16()  \n",
    "vgg16_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3099877",
   "metadata": {},
   "source": [
    "Una vez hecho esto, vamos a ver un resumen del modelo creado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2326254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              2101248   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 100)               409700    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,006,948\n",
      "Trainable params: 34,006,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247501f",
   "metadata": {},
   "source": [
    "Ahora el número de parámetros ha crecido sustancialmente (34 millones). Ahora sólo queda entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf8be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   9/1563 [..............................] - ETA: 24:26 - loss: 4.6052 - acc: 0.0104 - mse: 0.0099"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\INVITA~1\\AppData\\Local\\Temp/ipykernel_5836/3471044595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg16_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train_resized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_resized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16 = vgg16_model.fit(x=x_train_resized, y=y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_test_resized, y_test), shuffle=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf644ab6",
   "metadata": {},
   "source": [
    "Obviaremos la evaluación.\n",
    "\n",
    "Veamos las métricas obtenidas para el entrenamiento y validación gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(vgg16.history['acc'],'r')  \n",
    "plt.plot(vgg16.history['val_acc'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.figure(1)  \n",
    "plt.plot(vgg16.history['loss'],'r')  \n",
    "plt.plot(vgg16.history['val_loss'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Training Loss vs Validation Loss\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db40662",
   "metadata": {},
   "source": [
    "La generalización mejora a un 1% aproximadamente respecto a la red convolucional del experimento anterior, si bien, después de 10 epochs no ha mejorado las métricas estándar.\n",
    "\n",
    "Matriz de confusión\n",
    "Pasemos ahora a ver la matriz de confusión y las métricas de Accuracy, Recall y F1-score.\n",
    "\n",
    "Vamos a hacer una predicción sobre el dataset de validación y, a partir de ésta, generamos la matriz de confusión y mostramos las métricas mencionadas anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pred = vgg16_model.predict(x_test_resized, batch_size=32, verbose=1)  \n",
    "vgg16_predicted = np.argmax(vgg16_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea21870",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vamos a dar como predicha el mayor valor de la predicción. Lo normal es dar un valor mínimo o bias que defina un resultado como positivo, pero en este caso, lo vamos a hacer simple.\n",
    "\n",
    "Con la librería Scikit Learn, generamos la matriz de confusión y la dibujamos (aunque el gráfico no es muy bueno debido al numero de etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2062254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la matriz de confusión\n",
    "vgg16_cm = confusion_matrix(np.argmax(y_test, axis=1), vgg16_predicted)\n",
    "\n",
    "# Visualiamos la matriz de confusión\n",
    "vgg16_df_cm = pd.DataFrame(vgg16_cm, range(100), range(100))  \n",
    "plt.figure(figsize = (20,14))  \n",
    "sn.set(font_scale=1.4) #for label size  \n",
    "sn.heatmap(vgg16_df_cm, annot=True, annot_kws={\"size\": 12}) # font size  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1cfa2",
   "metadata": {},
   "source": [
    "Y por último, mostramos las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_report = classification_report(np.argmax(y_test, axis=1), vgg16_predicted)  \n",
    "print(vgg16_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fdec34",
   "metadata": {},
   "source": [
    "Curva ROC (tasas de verdaderos positivos y falsos positivos)\n",
    "Vamos a codificar la curva ROC para clasificación multiclase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification  \n",
    "from sklearn.preprocessing import label_binarize  \n",
    "from scipy import interp  \n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 100\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()  \n",
    "tpr = dict()  \n",
    "roc_auc = dict()  \n",
    "for i in range(n_classes):  \n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], vgg16_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), vgg16_pred.ravel())  \n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)  \n",
    "for i in range(n_classes):  \n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr  \n",
    "tpr[\"macro\"] = mean_tpr  \n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(n_classes-97), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlim([0.0, 1.0])  \n",
    "plt.ylim([0.0, 1.05])  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)  \n",
    "plt.xlim(0, 0.2)  \n",
    "plt.ylim(0.8, 1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(3), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eec6a1",
   "metadata": {},
   "source": [
    "Vamos a ver algunos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(x_train_original[0])  \n",
    "plt.show()  \n",
    "print('class for image 1: ' + str(np.argmax(y_test[0])))  \n",
    "print('predicted:         ' + str(vgg16_predicted[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3329eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(x_train_original[3])  \n",
    "plt.show()  \n",
    "print('class for image 3: ' + str(np.argmax(y_test[3])))  \n",
    "print('predicted:         ' + str(vgg16_predicted[3]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b5d5d",
   "metadata": {},
   "source": [
    "Salvaremos los datos del histórico de entrenamiento para compararlos con otros modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histórico\n",
    "with open(path_base + '/vgg16_history.txt', 'wb') as file_pi:  \n",
    "  pickle.dump(scnn.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03a661",
   "metadata": {},
   "source": [
    "VGG-19\n",
    "Definamos el modelo y entrenemos de la misma forma que VGG-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba77ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg19():  \n",
    "  model = vgg19.VGG19(include_top=True, weights=None, input_tensor=None, input_shape=(48,48,3), pooling=None, classes=100)\n",
    "\n",
    "  return model\n",
    "\n",
    "vgg19_model = create_vgg19()  \n",
    "vgg19_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef743ae",
   "metadata": {},
   "source": [
    "Una vez hecho esto, vamos a ver un resumen del modelo creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66731a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c2efc",
   "metadata": {},
   "source": [
    "Ahora sólo queda entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = vgg19_model.fit(x=x_train_resized, y=y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_test_resized, y_test), shuffle=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4918ad3",
   "metadata": {},
   "source": [
    "Obviaremos la evaluación.\n",
    "\n",
    "Veamos las métricas obtenidas para el entrenamiento y validación gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74173b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(vgg19.history['acc'],'r')  \n",
    "plt.plot(vgg19.history['val_acc'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.figure(1)  \n",
    "plt.plot(vgg19.history['loss'],'r')  \n",
    "plt.plot(vgg19.history['val_loss'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Training Loss vs Validation Loss\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e7471",
   "metadata": {},
   "source": [
    "Matriz de confusión\n",
    "Pasemos ahora a ver la matriz de confusión y las métricas de Accuracy, Recall y F1-score.\n",
    "\n",
    "Vamos a hacer una predicción sobre el dataset de validación y, a partir de ésta, generamos la matriz de confusión y mostramos las métricas mencionadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaae2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_pred = vgg19_model.predict(x_test_resized, batch_size=32, verbose=1)  \n",
    "vgg19_predicted = np.argmax(vgg19_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6abadd",
   "metadata": {},
   "source": [
    "vamos a dar como predicción el mayor valor. Lo normal es dar un valor mínimo o bias que defina un resultado como positivo, pero en este caso, lo vamos a hacer simple.\n",
    "\n",
    "Con la librería Scikit Learn, generamos la matriz de confusión y la dibujamos (aunque el gráfico no es muy bueno debido al numero de etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la matriz de confusión\n",
    "vgg19_cm = confusion_matrix(np.argmax(y_test, axis=1), vgg19_predicted)\n",
    "\n",
    "# Visualiamos la matriz de confusión\n",
    "vgg19_df_cm = pd.DataFrame(vgg19_cm, range(100), range(100))  \n",
    "plt.figure(figsize = (20,14))  \n",
    "sn.set(font_scale=1.4) #for label size  \n",
    "sn.heatmap(vgg19_df_cm, annot=True, annot_kws={\"size\": 12}) # font size  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c8d28",
   "metadata": {},
   "source": [
    "Y por último, mostramos las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1130826",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_report = classification_report(np.argmax(y_test, axis=1), vgg19_predicted)  \n",
    "print(vgg19_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0e12b0",
   "metadata": {},
   "source": [
    "Curva ROC (tasas de verdaderos positivos y falsos positivos)\n",
    "Vamos a codificar la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13453555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification  \n",
    "from sklearn.preprocessing import label_binarize  \n",
    "from scipy import interp  \n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 100\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()  \n",
    "tpr = dict()  \n",
    "roc_auc = dict()  \n",
    "for i in range(n_classes):  \n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], vgg19_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), vgg19_pred.ravel())  \n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)  \n",
    "for i in range(n_classes):  \n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr  \n",
    "tpr[\"macro\"] = mean_tpr  \n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(n_classes-97), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlim([0.0, 1.0])  \n",
    "plt.ylim([0.0, 1.05])  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)  \n",
    "plt.xlim(0, 0.2)  \n",
    "plt.ylim(0.8, 1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(3), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574a5e7",
   "metadata": {},
   "source": [
    "Vamos a ver algunos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501056f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(x_train_original[0])  \n",
    "plt.show()  \n",
    "print('class for image 1: ' + str(np.argmax(y_test[0])))  \n",
    "print('predicted:         ' + str(vgg19_predicted[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e042adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(x_train_original[3])  \n",
    "plt.show()  \n",
    "print('class for image 3: ' + str(np.argmax(y_test[3])))  \n",
    "print('predicted:         ' + str(vgg19_predicted[3]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef746154",
   "metadata": {},
   "source": [
    "Salvaremos los datos del histórico de entrenamiento para compararlos con otros modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histórico\n",
    "with open('vgg19_history.txt', 'wb') as file_pi:  \n",
    "  pickle.dump(scnn.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38251d73",
   "metadata": {},
   "source": [
    "A continuación, cargaremos las métricas obtenidas de anteriores modelos y los comparamos con los resultados actuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af051abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vgg16_history.txt', 'rb') as f:  \n",
    "  vgg16_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843cff5",
   "metadata": {},
   "source": [
    "Ya lo tenemos en las variables correspondientes. Ahora, comparemos las gráficas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_acc'],'r')  \n",
    "plt.plot(scnn_history['val_acc'],'g')  \n",
    "plt.plot(vgg16_history['val_acc'],'b')  \n",
    "plt.plot(vgg19.history['val_acc'],'y')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Simple NN Accuracy vs simple CNN Accuracy\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_loss'],'r')  \n",
    "plt.plot(scnn_history['val_loss'],'g')  \n",
    "plt.plot(vgg16.history['val_loss'],'b')  \n",
    "plt.plot(vgg19.history['val_loss'],'y')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Simple NN Loss vs simple CNN Loss\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_mean_squared_error'],'r')  \n",
    "plt.plot(scnn_history['val_mean_squared_error'],'g')  \n",
    "plt.plot(vgg16.history['val_mean_squared_error'],'b')  \n",
    "plt.plot(vgg19.history['val_mean_squared_error'],'y')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Mean Squared Error\")  \n",
    "plt.title(\"Simple NN MSE vs simple CNN MSE\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc9073",
   "metadata": {},
   "source": [
    "¿Qué ha pasado?\n",
    "Bien, la respuesta es sencilla. Hemos querido usar un modelo predeterminado, obligándonos a modificar la imagen original haciéndola más grande. Como la imagen es de 32x32 píxeles, pues la imagen resultante queda peor y aprende peor. Esto es, hemos cambiado el ámbito de los datos con respecto a los experimentos anteriores.\n",
    "\n",
    "Así que lo que tenemos que hacer, es una red VGG que no necesite modificar la imagen original.\n",
    "\n",
    "Custom VGG\n",
    "Definamos el modelo más específicamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d96697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_Without_lastPool(include_top=True, input_tensor=None, input_shape=(32,32,3), pooling=None, classes=100):  \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)  #to 16x16\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x) #to 8x8\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x) #to 4x4\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x) #to 2x2\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    #x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, x, name='vgg16Bis')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07862f",
   "metadata": {},
   "source": [
    "Compilamos como hasta ahora..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16WithoutPool():  \n",
    "  model = VGG16_Without_lastPool(include_top=True, input_tensor=None, input_shape=(32,32,3), pooling=None, classes=100)\n",
    "\n",
    "  return model\n",
    "\n",
    "vgg16Bis_model = create_vgg16WithoutPool()  \n",
    "vgg16Bis_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edce3d",
   "metadata": {},
   "source": [
    "Una vez hecho esto, vamos a ver un resumen del modelo creado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de745ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Bis_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf1f58",
   "metadata": {},
   "source": [
    "Tenemos uno más, 40 millones de parámetros, porque en realidad, sólo hemos quitado el Pool del bloque 5. Ahora sólo queda entrenar, pero esta vez con el dataset original normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc261c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Bis = vgg16Bis_model.fit(x=x_train, y=y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_test, y_test), shuffle=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f556f",
   "metadata": {},
   "source": [
    "Veamos las métricas obtenidas para el entrenamiento y validación gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(vgg16Bis.history['acc'],'r')  \n",
    "plt.plot(vgg16Bis.history['val_acc'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.figure(1)  \n",
    "plt.plot(vgg16Bis.history['loss'],'r')  \n",
    "plt.plot(vgg16Bis.history['val_loss'],'g')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Training Loss vs Validation Loss\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e84fa3",
   "metadata": {},
   "source": [
    "Matriz de confusión\n",
    "Pasemos ahora a ver la matriz de confusión y las métricas de Accuracy, Recall y F1-score.\n",
    "\n",
    "Vamos a hacer una predicción sobre el dataset de validación y, a partir de ésta, generamos la matriz de confusión y mostramos las métricas mencionadas anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0046d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Bis_pred = vgg16Bis_model.predict(x_test, batch_size=32, verbose=1)  \n",
    "vgg16Bis_predicted = np.argmax(vgg16Bis_pred, axis=1)\n",
    "\n",
    "vgg_cm = confusion_matrix(np.argmax(y_test, axis=1), vgg16Bis_predicted)\n",
    "\n",
    "# Visualizing of confusion matrix\n",
    "vgg_df_cm = pd.DataFrame(vgg_cm, range(100), range(100))  \n",
    "plt.figure(figsize = (20,14))  \n",
    "sn.set(font_scale=1.4) #for label size  \n",
    "sn.heatmap(vgg_df_cm, annot=True, annot_kws={\"size\": 12}) # font size  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d747b",
   "metadata": {},
   "source": [
    "Y por último, mostramos las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_report = classification_report(np.argmax(y_test, axis=1), vgg16Bis_predicted)  \n",
    "print(vgg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8656f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Curva ROC (tasas de verdaderos positivos y falsos positivos)\n",
    "Vamos a codificar de nuevo la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification  \n",
    "from sklearn.preprocessing import label_binarize  \n",
    "from scipy import interp  \n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 100\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()  \n",
    "tpr = dict()  \n",
    "roc_auc = dict()  \n",
    "for i in range(n_classes):  \n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], vgg16Bis_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), vgg16Bis_pred.ravel())  \n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)  \n",
    "for i in range(n_classes):  \n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr  \n",
    "tpr[\"macro\"] = mean_tpr  \n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(n_classes-97), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlim([0.0, 1.0])  \n",
    "plt.ylim([0.0, 1.05])  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)  \n",
    "plt.xlim(0, 0.2)  \n",
    "plt.ylim(0.8, 1)  \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],  \n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],  \n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])  \n",
    "for i, color in zip(range(3), colors):  \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')  \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2a2e1",
   "metadata": {},
   "source": [
    "Salvaremos los datos del histórico de entrenamiento para compararlos con otros modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79469dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histórico\n",
    "with open('cvgg16_history.txt', 'wb') as file_pi:  \n",
    "  pickle.dump(scnn.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b1095",
   "metadata": {},
   "source": [
    "A continuación, vamos a comparar las métricas con los modelos anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_acc'],'r')  \n",
    "plt.plot(scnn_history['val_acc'],'g')  \n",
    "plt.plot(vgg16.history['val_acc'],'b')  \n",
    "plt.plot(vgg19.history['val_acc'],'y')  \n",
    "plt.plot(vgg16Bis.history['val_acc'],'m')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Simple NN Accuracy vs simple CNN Accuracy\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19','Custom VGG'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_loss'],'r')  \n",
    "plt.plot(scnn_history['val_loss'],'g')  \n",
    "plt.plot(vgg16.history['val_loss'],'b')  \n",
    "plt.plot(vgg19.history['val_loss'],'y')  \n",
    "plt.plot(vgg16Bis.history['val_loss'],'m')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Simple NN Loss vs simple CNN Loss\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19','Custom VGG'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(snn_history['val_mean_squared_error'],'r')  \n",
    "plt.plot(scnn_history['val_mean_squared_error'],'g')  \n",
    "plt.plot(vgg16.history['val_mean_squared_error'],'b')  \n",
    "plt.plot(vgg19.history['val_mean_squared_error'],'y')  \n",
    "plt.plot(vgg16Bis.history['val_mean_squared_error'],'m')  \n",
    "plt.xticks(np.arange(0, 11, 2.0))  \n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Mean Squared Error\")  \n",
    "plt.title(\"Simple NN MSE vs simple CNN MSE\")  \n",
    "plt.legend(['simple NN','CNN','VGG 16','VGG 19','Custom VGG'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b35a7",
   "metadata": {},
   "source": [
    "Conclusión sobre el segundo Trabajo Realizado\n",
    "Hemos visto unos modelos más profundos, en los que el número de parámetros ha aumentado en exceso incluso para una red convolutiva. Además, el aprendizaje es mucho más lento en este caso específico. Quizás, a la vista de los resultados, sería planteable aumentar el número de epochs a realizar, pero en cambio, sabemos que actualmente existen modelos mejores que vamos a ver."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
